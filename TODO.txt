# Priorities

* Update on CRAN

* Update Shiny Apps tutorial and document its creation. Update it regularly. Maybe automate this as a Github Action? You can currently get to this via the website, under Tutorials menu item.

## write_answers()

See the comments at test-write_answers.R for detailed discussion. 

We should split write_answers() into two parts. The first part just grabs everything we need from the session and returns a tibble. (This part might be too big for CRAN.) The second part takes the tibble and outputs the answers as html/pdf/rds. We can test this a lot. Do this first. The current test case will help ensure that, at least, nothing is worse.

Change write_answers() to get rid of test mode since, with changes in exported learnr functions, this hack may no longer be necessary. 

Do we really need gridExtra in order to be able to create a pdf file? Seems like overkill. Must be an easier way.

A different approach to the pdf file creation problem in write_answers() would be to create the Rmd document on the file as a character object rmd and then do render(text = rmd, output_file = filename).

## Other items

* Fix Mac checking error on Github. Problem is "Error: Error: Error installing package 'textshaping':"

* Add a test case which ensures that downloading the answers actually works. I got caught with a bug on this when I stopped exporting write_answers(). That change caused the download buttons to fail, but I did not know it until someone reported it.

* Do we really need to import stringr? Other packages like tibble and dplyr? purrrr? readr??? Get rid of them, if possible!

* When running a tutorial from the Tutorial tab, links in the tutorial do not work.

* Something in Getting Started which shows how links work. You can click. It takes you away, but then the back button takes you back. Or maybe this doesn't work from the Tutorial tab?

* Ensure that this code handles our test code chunks in non-code questions. See RStudio and Github (gert) for examples. Seems to work, but some test cases would be nice.

* Would be nice to have more flexibility with knit_tutorials(). The problem arises when knitting a collection of tutorial paths takes too long, especially on CRAN, where all tests should only take 10 minutes total. Might be nice if tutorial paths:

  + Had an option to report the time (or start/end time) which each knitting used. We want to identify which tutorials take too long to knit. Right now, there is no easy way to do so.
  + Had an option to take a vector of tutorials to not knit, if they are in the input collection. That is, 

* Start working on a new function, process_submissions(), in a file called process_submissions.R. Starts by taking one argument which is a path to a folder with a bunch of answer html files in it. Reads through those files, pulling out the name of the tutorial, the email of the student, and the time it took. Then returns a tibble with that information in three variables.

* Understand https://r-pkgs.org/testing-basics.html#sec-snapshot-tests and other advanced testing stuff. I bet that "withr::local_options" will be valuable for doing the next two tasks.

* Need a test case for set_rstudio_settings(). Maybe record the settings of each variable, then change them, then check to see if you did change them, then change them back. Maybe use some advanced testthat tricks for frameworks or whatever. Maybe snapshots help? 

* A test case for set_binary...() as well. This requires more sophisticated R testing tools than we currently use with the package. Need to ensure that the option is set back, after the test runs, to the value it was before the test started. Or maybe there is some other way of setting this preference (with writePreference()?) without the hackorama of changing the user's Rprofile.

* Use testing_package() rather than hard-coding the package name.

* Read https://testthat.r-lib.org/articles/test-fixtures.html

* rstudioapi::is_available()

* With rstudioapi, use selectFile and friends as an easier way of saving student answers.

* I think that there is a bug in set_binary_only_in_r_profile() which only hits in a renv environment. It appears to check the .Rprofile in the local directory to see if options(pkgType = 'binary') is there, and then, when it is not there, it add the line to the main .Rprofile in the users home directory. If you run it again, it adds it again. A student can quickly get the line repeated many times. This then generates a weird error when the student restarts R, presumably because R does not like such silly repetition.

* Deal with these NOTES from devtools::check_win_devel() (or maybe they are from devtools::check(remote = TRUE, manual = TRUE) or rhub::check_for_cran())

* checking examples ... [11s] NOTE
Examples with CPU (user + system) or elapsed time > 5s
               user system elapsed
knit_tutorials 3.09   0.69    5.81
* checking for non-standard things in the check directory ... NOTE
Found the following files/directories:
  ''NULL''
* checking for detritus in the temp directory ... NOTE
Found the following files/directories:
  'lastMiKTeXException'
  
  * Why does devtools::check(remote = TRUE, manual = TRUE) produce so many weird notes about html problems? And why does it launch XQuartz?

* Provide a `skip` argument to knit_tutorials which allows it to skip any tutorial path which includes a specific string. This will generally be used like skip = c("06-data-tidying", "08-data-import"). Note that these are not the names of tutorial files (which are mostly "tutorial.Rmd") nor the full path to those tutorials (which we don't know until we run `return_tutorial_paths()`). Instead, they are strings from within the path. (Maybe require that they be full parts of the path? Or maybe any match is fine?)

* Figure out why Check is 0/0/0 but Test is 1 FAIL and 4 SKIPs.

# learnr stuff

learnr::get_tutorial_info() returns an ordinary list, with an `items` entry that is a "data frame with columns order, label, type and data describing the items (questions and exercises) in the tutorial." Right now, we only use this to get the value of `tutorial_id`. 

learnr::get_tutorial_state() is a complex function. See the help page for details. "Note that get_tutorial_state() will only work for the tutorial author and must be used in a reactive context, i.e. within shiny::observe(), shiny::observeEvent(), or shiny::reactive(). Any logic observing the user's tutorial state must be written inside a context="server" chunk in the tutorial's R Markdown source."

The result is a reactiveValues object. Huh? The names of the object correspond to the labels of the questions/exercises. 

The **downloadthis** package looks very interesting. It seems easy to download a file without all the rigamarole of the Shiny server. But it requires that the file exists. Can we automatically run the code to create the files? Yes! We can write the code in the final exercise and then tell students to hit Run Code. They can then hit the download button. But would that really work? Isn't an Exercise code chunk its own separate world, with no notion of the tutorial of which it is a part? Maybe the same local{()} nonsense that we use submission_server() would do the trick. But that would make for some ugly code. Maybe we can hide the code, but they still press the Run Code button.

Arrg. Neither learnr::get_tutorial_state() nor learnr::get_tutorial_info() seem to work in an Exercise code chunk, as perhaps I should have expected.


Does build_tutorials() really work? First, it seems to fail if you don't provide a url. Second, it does not seem to make use of a source option if one is provided.

Look at get_submissions_from_learnr_session() function. It is only used in one function. Is it still necessary?

Add test cases for format_tutorial() (at least) and maybe, if it is possible, for check_current_tutorial().

Do something about test-return_tutorial_paths(). 

Want to change the color to the OK box so that it is green when students enter
their email or other text. This seem relevant:

# https://stackoverflow.com/questions/33620133/change-the-color-of-action-button-in-shiny/35871042
Maybe testing_package() or skip_if_offline() would be useful. 

test_path() does not work if the file is not in tests/testthat/. Might still be useful since it means we don't need to setwd() to play with testing interactively.

Explore tutorial testing: https://pkgs.rstudio.com/learnr/articles/exercises.html#test-code-or-cases

The latest version of learnr seems to allow for ____ as a useful placeholder in code which is left in the actual exercise code blocks without creating an error. Might be useful! Might be much better than always inserting code from previous question.

So, in addition to hints, we could have each code block pre-populated with the code we want them to start with. No need for copy-code from previous exercise!


Testing for make_exercise() is a mess. This might be connected to some poor design of the function itself. But it also seems like rstudioapi functions might be problematic to test for some reason.

format_tutorial is an interesting and complex function. Revisit and clean up.

Is get_submissions_from_learnr_session() still necessary? At the very least, the comments need to be cleaned up.

Instead of the code chunk trick to spit out the information and download material, maybe those should be created with new functions from tutorial.helpers. Or maybe the `includes` argument to `tutorial()` could solve this by adding this material at run time. See: https://rstudio.github.io/learnr/reference/tutorial.html The df_print option is also interesting.


# Think about using ___
Blanks are detected using regular expressions (since blanks may make the code unparsable), and learnrâ€™s default pattern is to detect three or more consecutive underscores. Authors can choose the pattern for detecting blanks with the exercise.blanks chunk option. Setting exercise.blanks = "[.]{2}[a-z]+[.]{2}", for example, would allow the author to use valid R syntax for blanks. The warning message shown to students calls out the blanks they need to fill in.

## This release of learnr includes a new question type, question_numeric().
# Thoughts on Code Inclusion
https://github.com/rstudio/learnr/discussions/774

Handle the code inclusion for student information, code button and download buttons differently. First, the copy-code button is just a bunch of css. We can include css directly via learnr YAML header.

output:
  learnr::tutorial:
    css: css/custom.css

But it seems like you need that css in every new package. But maybe that is OK! Is it really a good idea that each new package of learnr tutorials needs to load up tutorial.helpers, or even install it? Or is it that we need this css directory/file in every tutorial directory? That would get annoying fast!

Relevant links:
https://stackoverflow.com/questions/62764873/is-there-a-way-to-use-common-css-in-learnr-tutorials
https://github.com/rstudio/learnr/issues/679

Second, use `includes` in the YAML header to bring in the R code for the information and download R code. See:

https://pkgs.rstudio.com/rmarkdown/reference/includes.html

Not sure that this will work for the same reason. "paths for resources referenced from the in_header, before_body, and after_body parameters are resolved relative to the directory of the input document." So, we would need something like:

include:
  includes(before_body = "../../child_documents/info_section.Rmd")

But then we need these files installed in each new tutorial package we create. Is there an easy way to automate that? No! And, more importantly, we want to help people who are making one-off tutorials, ones which are not part of a package. So, we can't be sure that a relative path will work. Indeed, we are sure that it won't work!

Another approach would be to have two templates to choose from. The first is our current one, which assumes that the student has tutorial.helpers installed, which is something we can force if our tutorials are part of a package. The second would hard code the three components into the skeleton itself. Call it a "stand-alone" version. But is this plausible? You would need to include all the R code for things like submission_ui in the template itself . . .



## Deal with all this junk left over from the old details.Rmd.
## Get a better understanding of package locations
Keep in mind that there are (at least) two versions of **your.tutorial.package** installed on your machine. In my case (using **all.primer.tutorials**), we have

```{bash eval = FALSE}
> /Library/Frameworks/R.framework/Versions/4.1/Resources/library
```

and

```{bash eval = FALSE}
> /Users/dkane/Library/Caches/org.R-project.R/R/renv/library/all.primer.tutorials-07f29d85/R-4.2/aarch64-apple-darwin20"
```

The first is the default location for packages. This is where things go unless you do something special. The second is installed by `renv`, which was used within the **all.primer.tutorials** project. When you are working in your **all.primer.tutorials** project, as you generally will, the `renv` version of the **all.primer.tutorials** library is what you will be using. You can check this by running `.libPaths()`.

```{r eval = FALSE}
> .libPaths()
[1] "/Users/dkane/Library/Caches/org.R-project.R/R/renv/library/all.primer.tutorials-07f29d85/R-4.2/aarch64-apple-darwin20"
[2] "/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library"
```

Whenever you `library()` a package, R looks through, in order, the values returned by `.libPaths()`. **renv** sets things up so that the first item is its collection of packages. Note that these are placed in a weird location, including a temp directory named something like `all.primer.tutorials-07f29d85`. I am not sure how **renv** decided to create a new one of these. It does not delete the old ones. In the case of major breakdowns, deleting these directories by hand can fix things.


In order to implement copy-pasting for an exercise, you need to add the line `<button onclick = "transfer_code(this)">Copy previous code</button>` either before or after the exercise that you want to copy-paste to. This will add a button that looks like this:

```{r echo = FALSE}
knitr::include_graphics("images/copy-button.png")
```

The user just needs to click the button in order to copy the code from the previous exercise into the current one.

The downsides to the current approach are: 1) tutorial makers still have to include something in the Exercises and 2) the button would look much better on the toolbar section of the exercise, perhaps in between  `Start Over` and `Hint`..

## Comments on .Rbuildignore
For some reason, it is impossible to include comments in the `.Rbuildignore`, at least by using the "#" symbol. I think the key issue is that using `*` (or maybe a parenthesis) in a line which begins with `#` causes trouble. Regardless, here are some thoughts on the version we currently use in **all.primer.tutorials**.

We would like to ensure that all the junk files which end up in the `tutorials/*` directories are not included in the build. Such files are often large. They also run the risk of messing things up in that they might cause certain tests to pass for us but which would fail for anyone who downloads from Github. (The `.gitignore` file does a reasonable job of ensuring that such files do not end up on Github.)

The key line is:

````
tutorials/[^/]*/(?!(data|images|.*Rmd))
````

This excludes everything in any subdirectory of the tutorials directory except an `images` directory (a file named images would also be included) or a `data` directory or a file suffixed with `.Rmd`.


## Adding more libraries

If you are using a new library, there are several things you need to check. First, most obviously, you should install the package within the `your.package` directory. Second, you must use `library(X)` in the setup chunk within the `tutorial.Rmd` itself. Third, you need to run `renv::status()`. This should report that there is a new package which is not part of `renv.lock`. Then, you will need to run `renv::snapshot()` so that the `renv.lock` file is updated. Fourth, you need to add the package to the `DESCRIPTION` file, in the `Imports:` section. (And don't forget the comma when you do so.) If you don't do this, then R CMD check might work on your computer, where library X is already installed, but won't work in Github actions since it relies on the DESCRIPTION file to know which packages to install.

It makes sense to use high quality tools for these steps. For example, `renv::install()` is a better way of installing needed packages within the **renv** environment. `usethis::use_package()` updates the `DESCRIPTION` file to include the package.

We have seen weird situations in which even doing all of the above did not work. The required hack was to install the new package in your main (default) library. Now, it seems weird that this would help since, with **renv**, we should never be using that location. I suspect that there is a bug involved in the interaction between `R CMD check` and **renv**.



## Tour of the Package Functions

**submission_ui** is an HTML structure defined through Shiny, which is inserted to the end of every tutorial. It creates buttons to download submission reports in the forms of RDS and HTML.

**submission_server()** is a function that communicates with the Shiny server during a tutorial. It provides the download functions, **downloadHtml** and **downloadRds**, for the user interface to call when downloading submission reports.


**build_html** is a function that creates and downloads a tibble report of tutorial submissions in HTML.

**build_rds** is a function that creates and downloads an tibble report of tutorial submissions in RDS.

**get_submissions_from_learnr_session** is a function that gets submissions of the current tutorial session through **learnr** functions, specifically `learnr::get_all_state_objects()` and `learnr::submissions_from_state_objects()`. It returns a list of submission objects, each containing details about the question and answer.


**format_tutorial** is a function that takes a tutorial path and formats the code chunk labels into a standardized format.

**check_current_tutorial** is an add-in function that runs `format_tutorial()` on the current opened tutorial. It is a handy add-in for tutorial makers who want to make sure their chunk labels are correct.

**make_exercise** is an add-in function that creates a exercises with correctly formatted labels and general structure.


## Permanent objects

Permanent objects should be avoided, if possible. The problem is that each Exercise code chunk is its own "world." It knows nothing of any actions taken in previous code chunks, except for three exceptions:

1) Any objects created in the global "setup" code chunk are available in all Exercise code chunks. The annoying thing about this option is that we would, ideally like to have the objects created near --- in the Rmd --- to the Exercises which use them. This also means that we can only use names like "fit_1" or "pp" once in each tutorial.

2) Objects created in a setup chunk for just one exercise.

3) Objects created in a code chunk which is then referenced by using the exercise.setup code chunk option in any Exercise which needs access to these objects. This is probably the best approach.

But what about regular code chunks which are neither Exercise code chunks nor setup chunks. Do objects created there persist? Maybe! Sometimes!? My *sense* is that such objects are available when the tutorial is knitted. This is why we can show a plot at the end of a Section after creating it at the start. But such objects are not available at run time, which is why they are not seen in Exercises.

No aspect of the tutorials has given us more trouble than permanent objects. In particular, it sometimes seems like things will work with Run Document but not with Run Tutorial. Since students always do the latter, we need to test that way as well.

I am dissatisfied withe code for formating the chunk names. First, I am not so sure how well it handles non-standard code chunks, the ones outside the standard exercise/hint blocks, as, for example, the ones which display plots. Second, instead of its current behavior, it should first, check all the section names, confirming that they are all unique, and reporting an error if not. Then, it should reduce each section name to the shortest length which is still unique. (And those links might be quite long, for example in the dates/times tutorial.) Then, it would use these as the base for making the labels. The limit on 20 characters fails too often.

